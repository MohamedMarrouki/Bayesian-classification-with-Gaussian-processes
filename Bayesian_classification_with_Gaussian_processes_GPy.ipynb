{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "28049596",
      "metadata": {
        "id": "28049596"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a95b837a",
      "metadata": {
        "id": "a95b837a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.impute import SimpleImputer\n",
        "import requests\n",
        "from io import StringIO\n",
        "import GPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "dqSdZJnLQtOg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqSdZJnLQtOg",
        "outputId": "8bcefe42-8985-46db-95d3-8f8bfcec9510"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NumPy version: 1.25.2\n",
            "SciPy version: 1.11.1\n",
            "Scikit-learn version: 1.3.0\n"
          ]
        }
      ],
      "source": [
        "import numpy\n",
        "import scipy\n",
        "import sklearn\n",
        "print(f\"NumPy version: {numpy.__version__}\")\n",
        "print(f\"SciPy version: {scipy.__version__}\")\n",
        "print(f\"Scikit-learn version: {sklearn.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f7d8036",
      "metadata": {
        "id": "7f7d8036"
      },
      "source": [
        "## Data Load (PIMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4b21f83",
      "metadata": {
        "id": "f4b21f83"
      },
      "outputs": [],
      "source": [
        "def load_pima_dataset_full_features():\n",
        "    url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "    col_names = ['pregnancies', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
        "    df = pd.read_csv(url, header=None, names=col_names)\n",
        "    \n",
        "    feature_names = col_names[:-1]\n",
        "    X = df[feature_names].values\n",
        "    y = df['label'].values\n",
        "    y = np.where(y == 0, -1, 1)\n",
        "    \n",
        "    for col in ['glucose', 'bp', 'skin', 'insulin', 'bmi']:\n",
        "        col_index = col_names.index(col)\n",
        "        non_zero_values = X[:, col_index][X[:, col_index] != 0]\n",
        "        if non_zero_values.size > 0:\n",
        "            mean_val = non_zero_values.mean()\n",
        "            X[:, col_index][X[:, col_index] == 0] = mean_val\n",
        "        else:\n",
        "            X[:, col_index][X[:, col_index] == 0] = 0 \n",
        "    \n",
        "    return X, y, feature_names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cdd47f2",
      "metadata": {
        "id": "8cdd47f2"
      },
      "source": [
        "## Data Load (CRABS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b50c4eb3",
      "metadata": {
        "id": "b50c4eb3"
      },
      "outputs": [],
      "source": [
        "def load_crabs_dataset_all_features():\n",
        "    url = \"https://raw.githubusercontent.com/fernandomayer/data/master/crabs.csv\"\n",
        "    \n",
        "    df = pd.read_csv(\n",
        "        url,\n",
        "        sep=';',           # Use semicolon as the delimiter\n",
        "        header=0,          # The first row is the header\n",
        "        decimal=',',       # Use comma as the decimal separator\n",
        "        quotechar='\"',     # Handle double quotes around fields\n",
        "        engine='python'    # Python engine for robustness with custom separators/quotes\n",
        "    )\n",
        "\n",
        "    df = df.rename(columns={'especie': 'sp', 'sexo': 'sex'})\n",
        "\n",
        "    df['sp'] = df['sp'].astype(str).str.strip()\n",
        "    df['sex'] = df['sex'].astype(str).str.strip()\n",
        "    \n",
        "    print(f\"Crabs dataset: Unique 'sp' values before filtering: {df['sp'].unique()}\")\n",
        "\n",
        "    df = df[df['sp'].isin(['azul', 'laranja'])]\n",
        "    \n",
        "    if df.empty:\n",
        "        raise ValueError(\n",
        "            \"DataFrame is empty after filtering 'sp' column. \"\n",
        "            \"This indicates 'azul' or 'laranja' species might not be present or are malformed.\"\n",
        "        )\n",
        "\n",
        "    feature_columns = ['FL', 'RW', 'CL', 'CW', 'BD']\n",
        "\n",
        "    for col in feature_columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    \n",
        "    X = df[feature_columns].values\n",
        "    \n",
        "    if np.isnan(X).any():\n",
        "        print(\"Warning: NaNs found in Crabs features. Imputing with mean...\")\n",
        "        imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "        X = imputer.fit_transform(X)\n",
        "\n",
        "    y = np.where(df['sp'] == 'azul', 1, -1)\n",
        "    \n",
        "    return X, y, feature_columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5db4d073",
      "metadata": {
        "id": "5db4d073"
      },
      "source": [
        "## Sigmoid Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84bf54f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    x_clamped = np.clip(x, -500, 500) \n",
        "    return np.where(x_clamped >= 0, 1 / (1 + np.exp(-x_clamped)), np.exp(x_clamped) / (1 + np.exp(x_clamped)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7080157",
      "metadata": {
        "id": "a7080157"
      },
      "source": [
        "## Prediction with GP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff926954",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_and_predict_gp_with_gpy(X_train, y_train, X_test, feature_names):\n",
        "    n_features = X_train.shape[1]\n",
        "    \n",
        "    kernel = GPy.kern.Matern32(input_dim=n_features, variance=1.0, \n",
        "                               lengthscale=np.ones(n_features), ARD=True)\n",
        "    \n",
        "    # Définir des bornes pour les hyperparamètres\n",
        "    kernel.variance.constrain_bounded(np.exp(-3.0), np.exp(3.0))\n",
        "    kernel.lengthscale.constrain_bounded(np.exp(-3.0), np.exp(3.0))\n",
        "    \n",
        "    model = GPy.models.GPClassification(X_train, y_train.reshape(-1, 1), kernel=kernel)\n",
        "    \n",
        "    print(\"\\n--- Training Gaussian Process Model (using GPy) ---\")\n",
        "    print(\"Optimizing GP hyperparameters with GPy's internal optimizer...\")\n",
        "    \n",
        "    try:\n",
        "        model.optimize_restarts(num_restarts=50, optimizer='lbfgsb', max_iters=2000, verbose=False)\n",
        "    except np.linalg.LinAlgError as e:\n",
        "        print(f\"Optimization failed with LinAlgError: {e}. Trying again with default settings.\")\n",
        "        model.optimize(messages=False, max_iters=2000)\n",
        "    except Exception as e:\n",
        "        print(f\"Optimization failed with unexpected error: {e}. Trying again with default settings.\")\n",
        "        model.optimize(messages=False, max_iters=2000)\n",
        "\n",
        "\n",
        "    print(\"GP Optimization complete.\")\n",
        "    \n",
        "    optimal_sigma_f = np.sqrt(model.Mat32.variance.values[0])\n",
        "    optimal_length_scales = model.Mat32.lengthscale.values\n",
        "    \n",
        "    print(f\"  - Final Optimal sigma_f: {optimal_sigma_f:.3f}\")\n",
        "    for i, ls in enumerate(optimal_length_scales):\n",
        "        if i < len(feature_names):\n",
        "            print(f\"  - Final Optimal length_scale for '{feature_names[i]}': {ls:.3f}\")\n",
        "        else:\n",
        "            print(f\"  - Final Optimal length_scale {i}: {ls:.3f} (No corresponding feature name)\")\n",
        "\n",
        "    mean_f_s, var_f_s = model.predict(X_test)\n",
        "    \n",
        "    denominator_term = 1 + np.pi * var_f_s / 8\n",
        "    gp_probs = sigmoid(mean_f_s / np.sqrt(denominator_term + 1e-10))\n",
        "    \n",
        "    gp_probs = gp_probs.flatten()\n",
        "    \n",
        "    gp_y_pred = np.where(gp_probs > 0.5, 1, -1)\n",
        "    \n",
        "    return gp_y_pred, model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b791f84d",
      "metadata": {
        "id": "b791f84d"
      },
      "source": [
        "## Classification Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "941e3289",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_classification_pipeline(dataset_loader_func, visualize=False):\n",
        "    X, y, feature_names = dataset_loader_func()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # ---  MinMaxScaler ---\n",
        "    scaler = MinMaxScaler(feature_range=(-1, 1)) \n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    dataset_name = dataset_loader_func.__name__.replace(\"load_\", \"\").replace(\"_dataset\", \"\").replace(\"_full_features\", \"\").replace(\"_all_features\", \"\").title()\n",
        "    print(f\"================== {dataset_name} Dataset ==================\")\n",
        "    print(f\"Training on {X_train.shape[0]} samples, testing on {X_test.shape[0]} samples.\")\n",
        "    print(f\"Number of features: {X_train.shape[1]}\")\n",
        "\n",
        "    # --- Gaussian Process Model (using GPy) ---\n",
        "    gp_y_pred, gp_model = train_and_predict_gp_with_gpy(X_train, y_train, X_test, feature_names)\n",
        "    \n",
        "    gp_accuracy = accuracy_score(y_test, gp_y_pred)\n",
        "    print(f\"\\n>>> GP Test Accuracy: {gp_accuracy:.4f} <<<\")\n",
        "\n",
        "    \n",
        "    print(\"\\n--- Training Support Vector Machine (SVM) Model for Comparison ---\")\n",
        "    param_grid = {\n",
        "        'C': [0.1, 1, 10, 100],\n",
        "        'gamma': [1, 0.1, 0.01, 0.001],\n",
        "        'kernel': ['rbf']\n",
        "    }\n",
        "    \n",
        "    grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=0, cv=5)\n",
        "    print(\"Running GridSearchCV for SVM...\")\n",
        "    grid.fit(X_train, y_train)\n",
        "    \n",
        "    print(\"SVM GridSearch complete.\")\n",
        "    print(f\"  - Best SVM Parameters: {grid.best_params_}\")\n",
        "    \n",
        "    svm_y_pred = grid.predict(X_test)\n",
        "    svm_accuracy = accuracy_score(y_test, svm_y_pred)\n",
        "    print(f\"\\n>>> SVM Test Accuracy: {svm_accuracy:.4f} <<<\")\n",
        "    print(\"=\" * 60 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "b33f5e6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b33f5e6e",
        "outputId": "b2780164-da72-4231-8be3-28dc462f18fc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "reconstraining parameters Mat32.variance\n",
            "reconstraining parameters Mat32.lengthscale\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================== Pima Dataset ==================\n",
            "Training on 537 samples, testing on 231 samples.\n",
            "Number of features: 8\n",
            "\n",
            "--- Training Gaussian Process Model (using GPy) ---\n",
            "Optimizing GP hyperparameters with GPy's internal optimizer...\n",
            "GP Optimization complete.\n",
            "  - Final Optimal sigma_f: 2.458\n",
            "  - Final Optimal length_scale for 'pregnancies': 20.076\n",
            "  - Final Optimal length_scale for 'glucose': 2.868\n",
            "  - Final Optimal length_scale for 'bp': 11.079\n",
            "  - Final Optimal length_scale for 'skin': 20.071\n",
            "  - Final Optimal length_scale for 'insulin': 0.913\n",
            "  - Final Optimal length_scale for 'bmi': 2.902\n",
            "  - Final Optimal length_scale for 'pedigree': 3.847\n",
            "  - Final Optimal length_scale for 'age': 2.453\n",
            "\n",
            ">>> GP Test Accuracy: 0.6537 <<<\n",
            "\n",
            "--- Training Support Vector Machine (SVM) Model for Comparison ---\n",
            "Running GridSearchCV for SVM...\n",
            "SVM GridSearch complete.\n",
            "  - Best SVM Parameters: {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "\n",
            ">>> SVM Test Accuracy: 0.7446 <<<\n",
            "============================================================\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "reconstraining parameters Mat32.variance\n",
            "reconstraining parameters Mat32.lengthscale\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Crabs dataset: Unique 'sp' values before filtering: ['azul' 'laranja']\n",
            "Warning: NaNs found in Crabs features. Imputing with mean...\n",
            "================== Crabs Dataset ==================\n",
            "Training on 109 samples, testing on 47 samples.\n",
            "Number of features: 5\n",
            "\n",
            "--- Training Gaussian Process Model (using GPy) ---\n",
            "Optimizing GP hyperparameters with GPy's internal optimizer...\n",
            "GP Optimization complete.\n",
            "  - Final Optimal sigma_f: 4.482\n",
            "  - Final Optimal length_scale for 'FL': 1.187\n",
            "  - Final Optimal length_scale for 'RW': 20.086\n",
            "  - Final Optimal length_scale for 'CL': 20.082\n",
            "  - Final Optimal length_scale for 'CW': 0.959\n",
            "  - Final Optimal length_scale for 'BD': 1.992\n",
            "\n",
            ">>> GP Test Accuracy: 0.5319 <<<\n",
            "\n",
            "--- Training Support Vector Machine (SVM) Model for Comparison ---\n",
            "Running GridSearchCV for SVM...\n",
            "SVM GridSearch complete.\n",
            "  - Best SVM Parameters: {'C': 100, 'gamma': 1, 'kernel': 'rbf'}\n",
            "\n",
            ">>> SVM Test Accuracy: 0.9787 <<<\n",
            "============================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "run_classification_pipeline(load_pima_dataset_full_features, visualize=False)\n",
        "run_classification_pipeline(load_crabs_dataset_all_features, visualize=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35949a87",
      "metadata": {
        "id": "35949a87"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "asienv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
